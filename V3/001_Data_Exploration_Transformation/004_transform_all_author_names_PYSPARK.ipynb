{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44920190-9120-4ae8-858f-14f52b073315",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import boto3\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import unicodedata\n",
    "import unidecode\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nameparser import HumanName\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import IntegerType, StringType, FloatType, ArrayType, DoubleType, StructType, StructField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb2086b1-79ea-4dee-95c5-fc5b86ce8d3f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.catalog.clearCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f29191d-1059-4a1a-a42b-0a11e8599c1f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_save_path = \"<S3path>\"\n",
    "iteration_save_path = \"<S3path>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47f9abef-de4b-45bd-8d74-3d30740105f2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Getting all author data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd8285ae-ef88-4f9c-9219-369b4402e62d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "author_names = spark.read.parquet(f\"{base_save_path}static_affiliations\") \\\n",
    "    .select(F.col('paper_id').alias('work_id'), F.col('author_sequence_number').alias('seq_no'),\n",
    "        F.trim(F.col('original_author')).alias('original_author')) \\\n",
    "    .filter(F.col('original_author')!=\"\")\n",
    "author_names.cache().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea68a751-508c-4663-aafb-d7f5cad6663e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Transforming author names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0701c86-8137-4bd4-bee9-9d2154dd9e4c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def transform_author_name(author):\n",
    "    \"\"\"Function that takes in a raw author name and normalizes it before name disambiguation begins.\"\"\"\n",
    "\n",
    "    # Removing bad data at beginning of strings\n",
    "    if author.startswith(\"None \"):\n",
    "        author = author.replace(\"None \", \"\")\n",
    "    elif author.startswith(\"Array \"):\n",
    "        author = author.replace(\"Array \", \"\")\n",
    "\n",
    "    # Using python libraries to perform various normalizations\n",
    "    author = unicodedata.normalize('NFKC', author)\n",
    "    \n",
    "    author_name = HumanName(\" \".join(author.split()))\n",
    "\n",
    "    if (author_name.title == 'Dr.') | (author_name.title == ''):\n",
    "        temp_new_author_name = f\"{author_name.first} {author_name.middle} {author_name.last}\"\n",
    "    else:\n",
    "        temp_new_author_name = f\"{author_name.title} {author_name.first} {author_name.middle} {author_name.last}\"\n",
    "\n",
    "    new_author_name = \" \".join(temp_new_author_name.split())\n",
    "\n",
    "    author_names = new_author_name.split(\" \")\n",
    "    \n",
    "    # The following tries to make sure names are in the correct order (or at least an order that works for disambiguation)\n",
    "    if (author_name.title != '') : \n",
    "        final_author_name = new_author_name\n",
    "    else:\n",
    "        if len(author_names) == 1:\n",
    "            final_author_name = new_author_name\n",
    "        elif len(author_names) == 2:\n",
    "            if (len(author_names[1]) == 1) & (len(author_names[0]) > 3):\n",
    "                final_author_name = f\"{author_names[1]} {author_names[0]}\"\n",
    "            elif (len(author_names[1]) == 2) & (len(author_names[0]) > 3):\n",
    "                if (author_names[1][1]==\".\"):\n",
    "                    final_author_name = f\"{author_names[1]} {author_names[0]}\"\n",
    "                else:\n",
    "                    final_author_name = new_author_name\n",
    "            else:\n",
    "                final_author_name = new_author_name\n",
    "        elif len(author_names) == 3:\n",
    "            if (len(author_names[1]) == 1) & (len(author_names[2]) == 1) & (len(author_names[0]) > 3):\n",
    "                final_author_name = f\"{author_names[1]} {author_names[2]} {author_names[0]}\"\n",
    "            elif (len(author_names[1]) == 2) & (len(author_names[2]) == 2) & (len(author_names[0]) > 3):\n",
    "                if (author_names[1][1]==\".\") & (author_names[2][1]==\".\"):\n",
    "                    final_author_name = f\"{author_names[1]} {author_names[2]} {author_names[0]}\"\n",
    "                else:\n",
    "                    final_author_name = new_author_name\n",
    "            else:\n",
    "                final_author_name = new_author_name\n",
    "        elif len(author_names) == 4:\n",
    "            if (len(author_names[1]) == 1) & (len(author_names[2]) == 1) & (len(author_names[3]) == 1) & (len(author_names[0]) > 3):\n",
    "                final_author_name = f\"{author_names[1]} {author_names[2]} {author_names[3]} {author_names[0]}\"\n",
    "            elif (len(author_names[1]) == 2) & (len(author_names[2]) == 2) & (len(author_names[3]) == 2) & (len(author_names[0]) > 3):\n",
    "                if (author_names[1][1]==\".\") & (author_names[2][1]==\".\") & (author_names[3][1]==\".\"):\n",
    "                    final_author_name = f\"{author_names[1]} {author_names[2]} {author_names[3]} {author_names[0]}\"\n",
    "                else:\n",
    "                    final_author_name = new_author_name\n",
    "            else:\n",
    "                final_author_name = new_author_name\n",
    "        else:\n",
    "            final_author_name = new_author_name\n",
    "    return final_author_name\n",
    "  \n",
    "def remove_current_author(author, coauthors):\n",
    "    return [x for x in coauthors if x!=author][:250]\n",
    "\n",
    "remove_current_author_udf = F.udf(remove_current_author,  ArrayType(StringType()))\n",
    "transform_author_name_udf = F.udf(transform_author_name, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1993f2c1-f6d6-418a-8e6d-c8306a1f015b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "author_names \\\n",
    "    .select('original_author') \\\n",
    "    .dropDuplicates() \\\n",
    "    .withColumn('transformed_name', transform_author_name_udf(F.col('original_author'))) \\\n",
    "    .write.mode('overwrite').parquet(f\"{iteration_save_path}final_model_data/author_name_transformations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54bf4b35-a7cd-4a18-b838-d4525ad984d9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Compiling Coauthors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e22107bd-631e-481c-8cb6-ac1d97ed093d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "author_name_transforms = spark.read \\\n",
    "    .parquet(f\"{iteration_save_path}final_model_data/author_name_transformations\")\n",
    "author_name_transforms.cache().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76e2cd6b-82a9-4f87-b64f-ffcbaf737074",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "author_names \\\n",
    "    .join(author_name_transforms, how='left', on='original_author') \\\n",
    "    .dropDuplicates(subset=['work_id','transformed_name']) \\\n",
    "    .groupby('work_id') \\\n",
    "    .agg(F.collect_list(F.col('transformed_name')).alias('all_authors')) \\\n",
    "    .write.mode('overwrite').parquet(f\"{iteration_save_path}final_model_data/all_authors_for_each_work\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c016822-a9c3-4729-9df3-bcde1339a8b4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Getting Author Name Index Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c35bf4e-1ab0-420e-adcf-59de776ac82c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "author_name_transforms = spark.read \\\n",
    "    .parquet(f\"{iteration_save_path}final_model_data/author_name_transformations\") \\\n",
    "    .select(F.col('transformed_name').alias('author_name')) \\\n",
    "    .dropDuplicates() \\\n",
    "    .filter(F.col('author_name')!='') \\\n",
    "    .withColumn(\"id\", F.monotonically_increasing_id())\n",
    "author_name_transforms.cache().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a32084bb-5f84-4a13-bf2e-0236a778a9a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "author_name_transforms \\\n",
    ".write.mode('overwrite').parquet(f\"{iteration_save_path}final_model_data/all_authors_for_each_work_indexed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61e44835-e28a-47fe-b5a4-3f62bdc669af",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Looking into different author name characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94f26718-fc19-4590-806b-ddd871542bdf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def check_latin_character(text):\n",
    "    try:        \n",
    "        str(text).encode('latin-1')\n",
    "        return 1\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4a8a822-a31e-44b9-a230-b8cb024dcf27",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@udf(returnType=FloatType())\n",
    "def check_latin_name(text):\n",
    "    text = text.replace(\" \", \"\").replace(\".\", \"\")\n",
    "    if text:\n",
    "        name_check = [check_latin_character(x) for x in text]\n",
    "        return sum(name_check)/len(name_check)\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23661f0a-2328-403e-af9f-048b443e120c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@udf(returnType=StringType())\n",
    "def transform_name_for_search(name):\n",
    "    name = unidecode.unidecode(unicodedata.normalize('NFKC', name))\n",
    "    name = name.lower().replace(\" \", \" \").replace(\".\", \" \").replace(\",\", \" \").replace(\"|\", \" \").replace(\")\", \"\").replace(\"(\", \"\")\\\n",
    "        .replace(\"-\", \"\").replace(\"&\", \"\").replace(\"$\", \"\").replace(\"#\", \"\").replace(\"@\", \"\").replace(\"%\", \"\").replace(\"0\", \"\") \\\n",
    "        .replace(\"1\", \"\").replace(\"2\", \"\").replace(\"3\", \"\").replace(\"4\", \"\").replace(\"5\", \"\").replace(\"6\", \"\").replace(\"7\", \"\") \\\n",
    "        .replace(\"8\", \"\").replace(\"9\", \"\").replace(\"*\", \"\").replace(\"^\", \"\").replace(\"{\", \"\").replace(\"}\", \"\").replace(\"+\", \"\") \\\n",
    "        .replace(\"=\", \"\").replace(\"_\", \"\").replace(\"~\", \"\").replace(\"`\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"\\\\\", \"\") \\\n",
    "        .replace(\"<\", \"\").replace(\">\", \"\").replace(\"?\", \"\").replace(\"/\", \"\").replace(\";\", \"\").replace(\":\", \"\").replace(\"\\'\", \"\") \\\n",
    "        .replace(\"\\\"\", \"\")\n",
    "    name = \" \".join(name.split())\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1694fc4-6fea-4547-9b26-ce8f3d831c58",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@udf(returnType=ArrayType(StringType()))\n",
    "def group_non_latin_characters(text):\n",
    "    groups = []\n",
    "    text = text.replace(\".\", \"\").replace(\" \", \"\")\n",
    "    for char in text:\n",
    "        try:\n",
    "            script = unicodedata.name(char).split(\" \")[0]\n",
    "            if script == 'LATIN':\n",
    "                pass\n",
    "            else:\n",
    "                if script not in groups:\n",
    "                    groups.append(script)\n",
    "        except:\n",
    "            if \"UNK\" not in groups:\n",
    "                groups.append(\"UNK\")\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7959e7b-8e31-46d9-83e5-bb374431efeb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@udf(returnType=IntegerType())\n",
    "def name_to_keep_ind(groups):\n",
    "    groups_to_skip = ['HIRAGANA', 'CJK', 'KATAKANA','ARABIC', 'HANGUL', 'THAI','DEVANAGARI','BENGALI',\n",
    "                      'THAANA','GUJARATI']\n",
    "    \n",
    "    if any(x in groups_to_skip for x in groups):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28645e87-0576-4238-bd6d-050e5b2cd5ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "author_names = spark.read.parquet(f\"{iteration_save_path}final_model_data/all_authors_for_each_work_indexed\") \\\n",
    "    .withColumn('latin_characters_per', check_latin_name(F.col('author_name'))) \\\n",
    "    .withColumn('transformed_search_name', transform_name_for_search(F.col('author_name'))) \\\n",
    "    .withColumn('name_len', F.length(F.col('transformed_search_name'))) \\\n",
    "    .filter(F.col('name_len')>1) \\\n",
    "    .withColumn('last_name', F.split(F.lower(F.col('transformed_search_name')), \" \")) \\\n",
    "    .select('author_name','transformed_search_name','latin_characters_per',\n",
    "            F.element_at(F.col('last_name'), -1).alias('last_name')) \\\n",
    "    .withColumn('transformed_last_name', transform_name_for_search(F.col('last_name'))) \\\n",
    "    .withColumn('non_latin_groups', group_non_latin_characters(F.col('author_name')))\n",
    "author_names.cache().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02ab3be1-e4a9-493d-8fd5-29f9455c2987",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "author_names \\\n",
    "    .withColumn('name_to_keep_ind', name_to_keep_ind('non_latin_groups')) \\\n",
    "    .filter(F.col('name_to_keep_ind')==1) \\\n",
    "    .withColumn('last_name_size', F.length(F.col('last_name'))) \\\n",
    "    .filter(F.col('last_name_size') > 1) \\\n",
    "    .select('last_name') \\\n",
    "    .dropDuplicates() \\\n",
    "    .write.mode('overwrite') \\\n",
    "    .parquet(f\"{iteration_save_path}final_model_data/block_creation/last_names_to_search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8efc4e5e-4780-4f9f-b1e9-709665ed713c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@udf(returnType=ArrayType(StringType()))\n",
    "def find_non_subsets(strings):\n",
    "    non_subsets = []\n",
    "    for i in range(len(strings)):\n",
    "        is_subset = False\n",
    "        for j in range(len(strings)):\n",
    "            if i != j:  # Avoid self-comparison\n",
    "                if strings[i] in strings[j]:\n",
    "                    is_subset = True\n",
    "                    break\n",
    "        if not is_subset:\n",
    "            non_subsets.append(strings[i])\n",
    "    return non_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2511d74c-42dd-4bcf-9bdc-557d96b22b69",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@udf(returnType=ArrayType(StringType()))\n",
    "def only_get_first_and_last(all_names):\n",
    "    if len(all_names) > 2:\n",
    "        return [all_names[0], all_names[-1]]\n",
    "    else:\n",
    "        return all_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b742254-a238-48d1-bb1e-ee64f02ba29a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "names_to_search = spark.read \\\n",
    "    .parquet(f\"{iteration_save_path}final_model_data/block_creation/last_names_to_search\") \\\n",
    "    .select(F.col('last_name').alias('block'))\n",
    "\n",
    "names_to_search.cache().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fedbca52-87c3-4bc4-a9d4-e832463cddd6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "author_names \\\n",
    "    .withColumn('name_to_keep_ind', name_to_keep_ind('non_latin_groups')) \\\n",
    "    .filter(F.col('name_to_keep_ind')==1) \\\n",
    "    .withColumn('potential_blocks', F.split(F.col('transformed_search_name'), \" \")) \\\n",
    "    .withColumn('potential_blocks', only_get_first_and_last(F.col('potential_blocks'))) \\\n",
    "    .select('transformed_search_name', 'potential_blocks') \\\n",
    "    .write.mode('overwrite') \\\n",
    "    .parquet(f\"{iteration_save_path}final_model_data/block_creation/names_to_be_blocked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2edcf9f-18c7-4376-bc9c-4328ae2a1adf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "author_names \\\n",
    "    .withColumn('name_to_keep_ind', name_to_keep_ind('non_latin_groups')) \\\n",
    "    .filter(F.col('name_to_keep_ind')==0) \\\n",
    "    .write.mode('overwrite') \\\n",
    "    .parquet(f\"{iteration_save_path}final_model_data/block_creation/names_to_not_be_blocked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2df1d31d-39f6-4cc4-b2ff-11c36f08ee6b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "author_names = spark.read.parquet(f\"{iteration_save_path}final_model_data/block_creation/names_to_be_blocked\") \\\n",
    "    .withColumn('potential_blocks', find_non_subsets(F.col('potential_blocks'))) \\\n",
    "    .select('transformed_search_name', F.explode('potential_blocks').alias('block')) \\\n",
    "    .withColumn('block_removed', F.expr(\"regexp_replace(transformed_search_name, block, '')\")) \\\n",
    "    .withColumn('new_block_removed', F.expr(\"regexp_replace(block_removed, ' ', '')\")) \\\n",
    "    .withColumn('letters_split', F.split(F.col('new_block_removed'), '(?!$)')) \\\n",
    "    .select('transformed_search_name','block',F.explode('letters_split').alias('letters_in_name')) \\\n",
    "    .dropDuplicates()\n",
    "author_names.cache().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a72ebe2a-e453-4df3-81f9-803e1760cd81",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "author_names \\\n",
    "    .show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57f4e930-7247-4b89-8e5c-3a8e21ba82c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "author_names \\\n",
    "    .join(names_to_search, how='inner', on='block') \\\n",
    "    .write.mode('overwrite') \\\n",
    "    .parquet(f\"{iteration_save_path}final_model_data/block_creation/names_blocked_to_name_check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25803e4e-7021-4263-b97d-fe9b0439a8a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "v3_transform_all_author_names_final",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
